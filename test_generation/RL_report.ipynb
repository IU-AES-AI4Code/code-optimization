{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report on Python code maintainability index (MI) improvement using LLMs project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Background for software metrics research\n",
    "\n",
    "### Background for LLM alignment research (SFT, PEFT, RLHF)\n",
    "\n",
    "### Background for code refactoring using AI\n",
    "\n",
    "### Our work \n",
    "\n",
    "In this work, we aim to apply RL-based alignment techniques (RLHF) to train code-pretrained LLMs improve a maintainability index metric for Python code. For that, we have collected our own data and have implemented a self-reward loop, allowing LLM to perform self-play on the metric improvement task, using MI score of the generated code as a reward indicator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
