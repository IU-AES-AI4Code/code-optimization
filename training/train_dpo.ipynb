{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3b09e3-a740-4a55-8876-bd498e6734d2",
   "metadata": {},
   "source": [
    "# Main Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24f2550c-8ce9-4143-80c3-525811b6edcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47d428492b746089962592773087da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# Setting CUDA visible devices to restrict model training to specific GPUs\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1,2,3\"\n",
    "\n",
    "# Loading the tokenizer for the model from the specified pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct\", device_map='auto')\n",
    "\n",
    "# Loading the pretrained model for causal language modeling\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"deepseek-ai/deepseek-coder-7b-instruct\",  # Model identifier or directory path\n",
    "    device_map='auto'  # Map tensors to specified devices (GPU or CPU)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a40a44-7c86-4908-9aa4-142850d6b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # Importing PyTorch library\n",
    "\n",
    "# Function to generate text based on input texts using a model\n",
    "def generate(input_texts, model):\n",
    "    # Encode input texts using the tokenizer and move tensors to GPU ('cuda')\n",
    "    encoded_input = tokenizer.batch_encode_plus(\n",
    "        input_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to('cuda')\n",
    "\n",
    "    # Generate text based on the encoded input using the model\n",
    "    output = model.generate(\n",
    "        **encoded_input,  # Unpack encoded input as keyword arguments\n",
    "        max_new_tokens=4096,  # Maximum number of tokens to generate\n",
    "        pad_token_id=tokenizer.eos_token_id,  # ID of the padding token\n",
    "        do_sample=True,  # Whether to sample from the distribution instead of using argmax\n",
    "        top_k=50,  # Number of top tokens to sample from\n",
    "        top_p=0.95,  # Cumulative probability for top-k sampling\n",
    "        use_cache=True  # Whether to use cached values in generation\n",
    "    )\n",
    "    \n",
    "    # Decode the generated output into text and remove special tokens\n",
    "    generated_texts = [\n",
    "        tokenizer.decode(\n",
    "            output[i][len(encoded_input['input_ids'][i]):],  # Exclude input text from generated output\n",
    "            skip_special_tokens=True  # Skip special tokens (like <eos>)\n",
    "        ).strip()  # Remove leading/trailing whitespace\n",
    "        for i in range(len(input_texts))  # Iterate over each input text\n",
    "    ]\n",
    "    \n",
    "    return generated_texts  # Return the generated texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f926be27-295b-4c37-905c-ca32cf488ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Function to sample implementations from files in a directory\n",
    "def sample_implementations(n_implemenations=50, dir='generated_code'):\n",
    "    # Get a list of all filenames in the specified directory (excluding .ipynb_checkpoints)\n",
    "    all_filenames = [filename for filename in os.listdir(dir) if filename != '.ipynb_checkpoints']\n",
    "    # Randomly select n_implemenations filenames from the list\n",
    "    filenames = np.random.choice(all_filenames, size=n_implemenations)\n",
    "    samples = []\n",
    "    # Read the content of each selected file and append it to the samples list\n",
    "    for filename in filenames:\n",
    "        with open(f'{dir}/{filename}') as f:\n",
    "            samples.append(f.read())\n",
    "    return samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e2741b-681b-4c52-8753-743ac0fb474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = sample_implementations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc765e2e-0c7b-491a-be7e-4ac419882aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load the description of Maintainability Index from file\n",
    "with open('mi_desc.txt') as f:\n",
    "    mi_desc = f.read()\n",
    "\n",
    "# Function to compose a prompt for rewriting code\n",
    "def compose_prompt_to_rewrite(code):\n",
    "    # Construct the instruction using the description of Maintainability Index and the provided code\n",
    "    instruction = f\"Here is a description of Maintainability Index:\\n\\n{mi_desc}\\n\\n\\\n",
    "    Here is a Python code whose maintainability index you need to improve:\\n\\n{code}\\n\\n\\\n",
    "    Please, rewrite the Python code given above so that its maintainability index is increased.\"\n",
    "\n",
    "    # Apply a chat template to the instruction using tokenizer\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [{ 'role': 'user', 'content': instruction}],\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=False\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# Function to rewrite a batch of code\n",
    "def rewrite_code_batch(code_batch, model, batch_size=5):\n",
    "    # Compose prompts for each code in the batch\n",
    "    prompts = [compose_prompt_to_rewrite(code) for code in code_batch]\n",
    "    output = []\n",
    "    # Generate responses for the prompts in batches\n",
    "    for i in tqdm(range(len(prompts)//batch_size)):\n",
    "        output += generate(prompts[i*batch_size:(i+1)*batch_size], model) \n",
    "    return output\n",
    "\n",
    "# Function to rewrite a batch of code and extract the rewritten code\n",
    "def rewrite_and_extract_code_batch(code_batch, model, batch_size=5):\n",
    "    # Rewrite the code batch using the model\n",
    "    rewritten_code_raw = rewrite_code_batch(code_batch, model, batch_size)\n",
    "    rewritten_code = []\n",
    "    skipped_samples_idx = [] \n",
    "    # Extract the rewritten code from the generated responses\n",
    "    for i, text in enumerate(rewritten_code_raw):\n",
    "        extracted_code = extract_code(text)\n",
    "        # Check if code extraction failed\n",
    "        if len(extracted_code) == 0:\n",
    "            print(f'Failed to extract code from the answer {i}')\n",
    "            skipped_samples_idx.append(i)\n",
    "            rewritten_code.append(\"\")\n",
    "        else:\n",
    "            rewritten_code.append(extracted_code[0])\n",
    "    return rewritten_code, rewritten_code_raw, skipped_samples_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60ac7ae2-6284-41f9-a04e-afa2086f5611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_code(code):\n",
    "    # Define a regular expression pattern to match Python code blocks within triple backticks\n",
    "    pattern = r'```python\\n(.*?)\\n```'\n",
    "    # Use re.findall() to find all matches of the pattern in the input code string\n",
    "    matches = re.findall(pattern, code, re.DOTALL)\n",
    "    # Return the matched code blocks as a list\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3877c5e0-dc49-4efd-97b0-697b658b2838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "def compute_mi(code):\n",
    "    # Constructing a dictionary containing the code\n",
    "    data = {\"code\": code}\n",
    "    # Converting the dictionary to JSON format\n",
    "    json_data = json.dumps(data)\n",
    "    \n",
    "    # Making a POST request to compute the maintainability index (MI)\n",
    "    new_response = requests.post(\n",
    "        # URL for the endpoint to compute MI (uncomment the appropriate line based on environment)\n",
    "        \"http://localhost:8002/compute_mi\",  # URL for local endpoint\n",
    "        data=json_data,  # Sending the JSON data in the request body\n",
    "        headers={'Content-Type': 'application/json'}  # Setting the request headers\n",
    "    )\n",
    "    \n",
    "    # Parsing the JSON response and returning it as a Python dictionary\n",
    "    return new_response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925fc000-1204-434c-b50a-2baea3de1de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from trl import DPOTrainer\n",
    "from transformers import TrainingArguments\n",
    "from datasets import Dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_kbit_training,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftModel\n",
    ")\n",
    "\n",
    "def compose_train_dataset(prompts, best_variants, worst_variants, original_variants):\n",
    "    # Identify indices of samples where the best variant is not better than the original\n",
    "    idx_to_skip = [\n",
    "        idx for idx in range(len(prompts))\n",
    "        if original_variants[idx]['mi'] > best_variants[idx]['mi']\n",
    "    ]\n",
    "    # Print a message if any samples are excluded from the training dataset\n",
    "    if len(idx_to_skip) != 0:\n",
    "        print(f'Samples {idx_to_skip} are excluded from training dataset because \\\n",
    "        their best variants are not actually better than original ones.')\n",
    "    # Create a Dataset object containing prompts, chosen (best variants), and rejected (worst variants)\n",
    "    return Dataset.from_dict({\n",
    "        'prompt': [prompts[idx] for idx in range(len(prompts)) if not idx in idx_to_skip],\n",
    "        'chosen': [best_variants[idx]['text_raw'] for idx in range(len(prompts)) if not idx in idx_to_skip],\n",
    "        'rejected': [worst_variants[idx]['text_raw'] for idx in range(len(prompts)) if not idx in idx_to_skip]\n",
    "    })\n",
    "\n",
    "def train(model, train_dataset, output_dir='./dpo_output_dir/'):\n",
    "    # Define configuration for the Lora model\n",
    "    peft_config = LoraConfig(\n",
    "        r=32,\n",
    "        lora_alpha=64,\n",
    "        lora_dropout=0.05,\n",
    "        target_modules=[  # Modules to apply PEFT on\n",
    "            \"q_proj\",\n",
    "            \"k_proj\",\n",
    "            \"v_proj\",\n",
    "            \"o_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"up_proj\",\n",
    "            \"down_proj\",\n",
    "            \"lm_head\"\n",
    "         ], \n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    # Prepare the base model for knowledge distillation\n",
    "    base_model = prepare_model_for_kbit_training(model)\n",
    "    # Create a PEFT model based on the base model and PEFT configuration\n",
    "    peft_model = get_peft_model(base_model, peft_config)\n",
    "    \n",
    "    # Define training arguments for the model\n",
    "    training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=1,\n",
    "        warmup_steps=25,\n",
    "        num_train_epochs=1,\n",
    "        do_eval=False,\n",
    "        learning_rate=3e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=50,\n",
    "        optim=\"adamw_torch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        output_dir=output_dir,\n",
    "        load_best_model_at_end=False,\n",
    "        report_to=\"none\",\n",
    "        remove_unused_columns=False,\n",
    "    )\n",
    "\n",
    "    # Create a DPOTrainer object for training\n",
    "    dpo_trainer = DPOTrainer(\n",
    "         model,\n",
    "         ref_model= None,\n",
    "         args=training_args,\n",
    "         peft_config=peft_config,\n",
    "         beta=0.1,\n",
    "         train_dataset=train_dataset,\n",
    "         tokenizer=tokenizer,  # Assuming `tokenizer` is defined elsewhere\n",
    "         max_prompt_length=4096,\n",
    "         max_length=2*4096,\n",
    "    )\n",
    "\n",
    "    # Train the model using DPOTrainer\n",
    "    dpo_trainer.train()\n",
    "\n",
    "    # Merge the trained model and unload the PEFT part\n",
    "    return dpo_trainer.model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b0252b-b7c0-4a65-9183-729b9bcf5f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "def dpo_iteration(\n",
    "    iteration_name,\n",
    "    model,\n",
    "    n_samples=10,\n",
    "    batch_size=2,\n",
    "    n_tries_to_rewrite=2,\n",
    "    original_code_dir='generated_code',\n",
    "    mi_hist_dir='dpo_mi/hist',\n",
    "    struct_dir='dpo_mi/struct',\n",
    "):\n",
    "\n",
    "    # Printing iteration name\n",
    "    print(f'=== Iteration {iteration_name} ===')\n",
    "\n",
    "    # Define a structure to store all the necessary data\n",
    "    struct = [\n",
    "        {\n",
    "            'code_variants': [\n",
    "                {\n",
    "                    'text': None,\n",
    "                    'text_raw': None,\n",
    "                    'is_original': False,\n",
    "                    'mi': None\n",
    "                }\n",
    "                for i in range(n_tries_to_rewrite + 1)\n",
    "            ],\n",
    "            'original_variant': None,\n",
    "            'best_variant': None,\n",
    "            'worst_variant': None,\n",
    "            # 'skip': False\n",
    "        }\n",
    "        for i in range(n_samples)\n",
    "    ]\n",
    "    \n",
    "    # 1. Sample several implementations from the dataset\n",
    "    # Printing progress message\n",
    "    print('--> Sampling code')\n",
    "    # Sampling original code from the dataset\n",
    "    original_code = sample_implementations(\n",
    "        n_implemenations=n_samples, dir=original_code_dir\n",
    "    )\n",
    "\n",
    "    # Store original code in the structure\n",
    "    for i, code in enumerate(original_code):\n",
    "        struct[i]['code_variants'][0]['text'] = code\n",
    "        struct[i]['code_variants'][0]['is_original'] = True\n",
    "        struct[i]['original_variant'] = struct[i]['code_variants'][0]\n",
    "    \n",
    "    # 2. Ask the model to rewrite the implementations to have higher MI\n",
    "    # Printing progress message\n",
    "    print('--> Asking to improve MI')\n",
    "    for attempt_idx in range(n_tries_to_rewrite):\n",
    "        # Printing attempt number\n",
    "        print(f'Attempt {attempt_idx}')\n",
    "        # Rewrite the original code using the model\n",
    "        rewritten_code, rewritten_code_raw, skipped_samples_idx = rewrite_and_extract_code_batch(\n",
    "            original_code, model,batch_size\n",
    "        )\n",
    "        # Store rewritten code in the structure\n",
    "        for i in range(len(rewritten_code)):\n",
    "            struct[i]['code_variants'][1+attempt_idx]['text'] = rewritten_code[i]\n",
    "            struct[i]['code_variants'][1+attempt_idx]['text_raw'] = rewritten_code_raw[i]\n",
    "\n",
    "    # 3. Calculate MIs for the implementations with higher MI\n",
    "    # Printing progress message\n",
    "    print('--> Calculating MI for code variants')\n",
    "    for i in range(len(struct)):\n",
    "        # Calculate maintainability index (MI) for each code variant\n",
    "        mi_json = compute_mi([variant['text'] for variant in struct[i]['code_variants']])\n",
    "        mi_values = [item['maintainability_index'] for item in mi_json]\n",
    "        # Store MI values in the structure\n",
    "        for j in range(len(struct[i]['code_variants'])):\n",
    "            struct[i]['code_variants'][j]['mi'] = mi_values[j]\n",
    "\n",
    "    # 4. Select best and worst variants in terms of MI\n",
    "    # Printing progress message\n",
    "    print('--> Choosing best and worst variants')\n",
    "    for i in range(len(struct)):\n",
    "        # Find the index of the variant with the highest MI\n",
    "        # It does not consider original variant\n",
    "        best_variant_idx = np.argmax([\n",
    "            variant['mi'] if variant['mi'] != None\n",
    "            else -np.inf\n",
    "            for variant in struct[i]['code_variants'][1:]  \n",
    "        ])\n",
    "        # Set best variant\n",
    "        struct[i]['best_variant'] = struct[i]['code_variants'][1 + best_variant_idx]\n",
    "        \n",
    "        # Find the index of the variant with the lowest MI\n",
    "        # It does not consider original variant\n",
    "        worst_variant_idx = np.argmin([\n",
    "            variant['mi'] if variant['mi'] != None\n",
    "            else np.inf\n",
    "            for variant in struct[i]['code_variants'][1:]  \n",
    "        ])\n",
    "        # Set worst variant\n",
    "        struct[i]['worst_variant'] = struct[i]['code_variants'][1 + worst_variant_idx]\n",
    "\n",
    "    # Save the histogram to a file\n",
    "    # Creating a new figure\n",
    "    plt.figure()\n",
    "    # Plotting histogram of MI values\n",
    "    plt.hist([item['worst_variant']['mi'] for item in struct], edgecolor='black')\n",
    "    # Setting labels and titles\n",
    "    plt.title('Distribution of Maintainability Index')  \n",
    "    plt.xlabel('Maintainability Index')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(f'{mi_hist_dir}/{iteration_name}.png')\n",
    "    # Displaying the plot\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Train the model on the pairs.\n",
    "    # Printing progress message\n",
    "    print('--> Training model')\n",
    "    prompts = [\n",
    "        compose_prompt_to_rewrite(code)\n",
    "        for i, code in enumerate(original_code)\n",
    "        if not i in skipped_samples_idx \n",
    "    ]\n",
    "\n",
    "    # Prepare necessary data for training\n",
    "    best_variants = [item['best_variant'] for item in struct]\n",
    "    worst_variants = [item['worst_variant'] for item in struct]\n",
    "    original_variants = [item['original_variant'] for item in struct]\n",
    "    # Compose a training dataset with prompts, code with high MI, and code with low MI\n",
    "    train_dataset = compose_train_dataset(prompts, best_variants, worst_variants, original_variants)\n",
    "    # Train for one epoch\n",
    "    model = train(model, train_dataset)\n",
    "    \n",
    "    # 6. Finish Iteration\n",
    "    # Printing progress message\n",
    "    print('--> Iteration finished\\n')\n",
    "    # Saving structure to a JSON file\n",
    "    with open(f'{struct_dir}/{iteration_name}.json', 'w') as f:\n",
    "        json.dump(struct, f)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30fa0ce4-2d10-4132-a322-366f8074fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Iteration 0 ===\n",
      "--> Sampling code\n",
      "--> Asking to improve MI\n",
      "Attempt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:33<00:00, 66.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract code from the answer 1\n",
      "Failed to extract code from the answer 8\n",
      "Failed to extract code from the answer 10\n",
      "Failed to extract code from the answer 28\n",
      "Attempt 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:56<00:00, 71.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to extract code from the answer 38\n",
      "Failed to extract code from the answer 41\n",
      "Failed to extract code from the answer 44\n",
      "--> Calculating MI for code variants\n",
      "--> Choosing best and worst variants\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Training model\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m dpo_iteration(i, model, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_tries_to_rewrite\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 138\u001b[0m, in \u001b[0;36mdpo_iteration\u001b[0;34m(iteration_name, model, n_samples, batch_size, n_tries_to_rewrite, original_code_dir, mi_hist_dir, struct_dir)\u001b[0m\n\u001b[1;32m    136\u001b[0m original_variants \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal_variant\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m struct]\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Compose a training dataset with prompts, code with high MI, and code with low MI\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m compose_train_dataset(prompts, best_variants, worst_variants, original_variants)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[1;32m    140\u001b[0m model \u001b[38;5;241m=\u001b[39m train(model, train_dataset)\n",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m, in \u001b[0;36mcompose_train_dataset\u001b[0;34m(prompts, best_variants, worst_variants, original_variants)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_train_dataset\u001b[39m(prompts, best_variants, worst_variants, original_variants):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Identify indices of samples where the best variant is not better than the original\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     idx_to_skip \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m         idx \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prompts))\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m original_variants[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m best_variants[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Print a message if any samples are excluded from the training dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx_to_skip) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompose_train_dataset\u001b[39m(prompts, best_variants, worst_variants, original_variants):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Identify indices of samples where the best variant is not better than the original\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     idx_to_skip \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m         idx \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(prompts))\n\u001b[0;32m---> 17\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m original_variants[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m best_variants[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmi\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Print a message if any samples are excluded from the training dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(idx_to_skip) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = dpo_iteration(i, model, n_samples=50, batch_size=10, n_tries_to_rewrite=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c054fe9-39ee-4c1b-8867-c4f3cab9a2e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf177eb7-a9eb-4407-823a-9bba4541cd1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncs_georgy",
   "language": "python",
   "name": "ncs_georgy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
